{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06aac7b",
   "metadata": {},
   "source": [
    "# 回帰と汎化性能\n",
    "フックの法則（バネの伸びとバネにかかる張力の比例）を例にとって**線形回帰**を学びました。\n",
    "> **線形回帰** \n",
    "> 予測する関数（**回帰関数**と呼びます）が一次関数（**線形関数**ともいいます）であることが予見される時に利用される回帰アルゴリズム\n",
    "\n",
    "回帰関数が一次関数でないとき、また、回帰関数のタイプが不明である時の回帰問題は、\n",
    "**カーネル**という手法を用いて解くことができます。\n",
    "\n",
    "カーネルとはデータ間の類似性を評価する関数（**類似度関数**）であり、\n",
    "**正定値性**と呼ばれる数学的な性質を満たします。\n",
    "> データ$x, y$に対して、\n",
    "カーネルは$x$と$y$の類似性を与える関す$k(x, y)$です。\n",
    "カーネルは次の用に定義される正定値性を満足します。\n",
    ">\n",
    ">任意のデータ$x_1, \\dots, x_n$と実数$c_1, \\dots, c_n$に対して、次の不等式が成り立つ。\n",
    ">\n",
    "> $$\n",
    "\\sum_{i=1}^n\\sum_{j=1}^n c_i c_j k(x_i, x_j) \\ge 0\n",
    "$$\n",
    "> \n",
    "\n",
    "SVMによる分類において、万能の類似度関数としてrbfを利用しましたが、\n",
    "rbfは代表的なカーネルの例です。\n",
    "\n",
    "## 例1\n",
    "次のプログラムを実行して、$y = x^2$のグラフを描いてみましょう。\n",
    "\n",
    "```python\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def f(x):\n",
    "    return x**2\n",
    "x = np.linspace(-3, 3, 1000)\n",
    "y = f(x)\n",
    "plt.plot(x, y)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea05d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e21b11a9",
   "metadata": {},
   "source": [
    "曲線$y = x^2$の周りに誤差を含んで確率的にばらつく50個の訓練データを作成します。\n",
    "> 各訓練データは$x$座標と$y$座標のペアです。\n",
    "\n",
    "```python\n",
    "n = 50\n",
    "train_x = np.linspace(-1, 1, n)\n",
    "train_y = f(train_x) + 0.5 * np.random.randn(n)\n",
    "train_x = train_x.reshape(-1,1) * 3\n",
    "train_y = train_y.reshape(-1,1) * 3\n",
    "plt.plot(train_x, train_y, 'o')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ed932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ee92ec6",
   "metadata": {},
   "source": [
    "次のプログラムは、この訓練データに対して線形回帰を実行します。\n",
    "\n",
    "プログラムの最終行では**決定係数**を表示します。\n",
    "決定係数は回帰関数の訓練データへの当てはまり度を表現する指標で、\n",
    "0から1の間の値を取り、\n",
    "1に近いほど正確に当てはまっていることを意味します。\n",
    "\n",
    "```python\n",
    "reg = LinearRegression()\n",
    "reg.fit(train_x, train_y)\n",
    "\n",
    "test_x = np.linspace(-3, 3, 1000).reshape(-1,1)\n",
    "test_y = reg.predict(test_x)\n",
    "\n",
    "plt.plot(train_x, train_y, 'o')\n",
    "plt.plot(test_x, test_y)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(reg.score(train_x, train_y))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff684fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc95646d",
   "metadata": {},
   "source": [
    "当然ですが、線形回帰ではうまく回帰できないことが分かります。\n",
    "決定係数も0に近いことが分かる筈です。\n",
    "\n",
    "一次式ではない回帰関数を探索したいときに役に立つのが**カーネル回帰**です。\n",
    "カーネル回帰の手法も一つではないのですが、\n",
    "ここではカーネルリッジ回帰（KernelRidge）を使います。\n",
    "\n",
    "```python\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "alpha = 10**-1\n",
    "gamma = 10**-1\n",
    "\n",
    "reg = KernelRidge(alpha=alpha, gamma=gamma, kernel='rbf')\n",
    "reg.fit(train_x, train_y)\n",
    "\n",
    "test_y = reg.predict(test_x)\n",
    "\n",
    "plt.plot(train_x, train_y, 'o')\n",
    "plt.plot(test_x, test_y)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(reg.score(train_x, train_y))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446abd10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fd596b6",
   "metadata": {},
   "source": [
    "かなり上手に二次曲線を近似していることが分かると思います。\n",
    "\n",
    "`alpha`と`gamma`は回帰関数の当てはまり具合を調整する**ハイパーパラメータ**です。\n",
    "\n",
    "例えば、\n",
    "```python\n",
    "alpha = 0\n",
    "gamma = 10**1\n",
    "```\n",
    "として、再度カーネルリッジ回帰を実行して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9cba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "539ba7ec",
   "metadata": {},
   "source": [
    "前の実行時に比較して、回帰関数の当てはまり度を表す決定係数は1に近くなっており、\n",
    "訓練データをより正確に表現できるようになっているのですが、\n",
    "回帰関数はかえって正解の関数（$y = x^2$）から乖離しています。\n",
    "\n",
    "正解関数からの乖離は予測の性能（**汎化性能**）を悪化させます。\n",
    "\n",
    "`alpha`と`gamma`の値を変化させて、\n",
    "汎化性能を最適化すると想われる値を探してみて下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1a3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9906cc85",
   "metadata": {},
   "source": [
    "## 例2\n",
    "もう少し複雑な例を見てみましょう。\n",
    "次の関数のグラフを$x$の値が$[-3, 3]の区間で描いてみて下さい。\n",
    "```python\n",
    "def f(x):\n",
    "    return x**2 + 5*np.sin(5 * np.pi * x)/np.exp(np.abs(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb515aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65aa333d",
   "metadata": {},
   "source": [
    "次に、この関数から50個の訓練データをサンプリングしますが、$y$の値には誤差が含まれるとします。\n",
    "> 各訓練データは$x$座標と$y$座標のペアです。\n",
    "\n",
    "サンプリングには次のプログラムを用います。\n",
    "```python\n",
    "n = 50\n",
    "train_x = np.linspace(-2, 2, n)\n",
    "train_y = f(train_x) + 0.5 * np.random.randn(n)\n",
    "```\n",
    "\n",
    "サンプリングした点をグラフにプロットしてみて下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d2c0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc1561e",
   "metadata": {},
   "source": [
    "カーネルリッジ回帰のハイパーパラメータ（`alpha`と`gamma`）の値を変化させて、\n",
    "正解の関数に近い回帰関数のグラフを描いて下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd4fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2532a2e",
   "metadata": {},
   "source": [
    "正解に近い回帰関数を与えるハイパーパラメータの探索は容易ではないことが分かります。\n",
    "\n",
    "定量的に**ハイパーパラメータ最適化**を実行する方法については、別の機会に学びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a859d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
