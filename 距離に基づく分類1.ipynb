{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備\n",
    "## ライブラリのインストール\n",
    "Colaboratory環境で実行する場合は`japanaize_matplotlib`をインストールする必要があります。\n",
    "\n",
    "SageMaker環境で以下を実行する必要はありませんが、実行しても害はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: japanize_matplotlib in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from japanize_matplotlib) (3.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (1.22.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (4.29.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (8.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->japanize_matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b79J21iz8d4"
   },
   "source": [
    "## ライブラリのインポート\n",
    "\n",
    "この資料で利用するライブラリを一括してインポートします。\n",
    "\n",
    "SageMakerやColaboratoryで接続がタイムアウトした時は、\n",
    "以下のセルを再度実行して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2511,
     "status": "ok",
     "timestamp": 1679962134584,
     "user": {
      "displayName": "大豆生田幹",
      "userId": "17706619674069057736"
     },
     "user_tz": -540
    },
    "id": "V6bMR59i0o5R",
    "outputId": "4010836c-2077-4cd4-96b3-9ffd5cd6b8b5"
   },
   "outputs": [],
   "source": [
    "#ライブラリーのインポート\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn import manifold\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import japanize_matplotlib\n",
    "import math\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Csyv8UbHNNuh"
   },
   "source": [
    "# 2章 距離関数による機械学習\n",
    "本章では1.4節で述べた「類似度に基づいて学習を行う機械学習のフレームワーク」に従い、著者当てゲームを実装していきます。\n",
    "\n",
    "機械学習ではモデルが正しい予測をすることが最も重要です。一方で、顕著な成果をあげている深層学習でモデルを解釈することができないように、モデルは人間にとって理解しやすいとは限りません。\n",
    "\n",
    "<font color= \"red\">**機械学習は探索の科学**</font>であり、探索の方法論を研究する学問領域です。仮説の検証が目的の統計学とは異なり、モデルの探索に重きを置いています。\n",
    "\n",
    "その探索対象は学習アルゴリズムだけではなく、データの加工方法や類似度関数など多岐にわたります。本章では以下で紹介する探索サイクルに沿って正確性の高いモデルを見つける過程で、機械学習についての基礎を身に着けることを目的としています。\n",
    "\n",
    "### 探索対象\n",
    "\n",
    "1. 特徴\n",
    "1. データの表現\n",
    "1. 類似度関数\n",
    "1. 学習アルゴリズムと最適ハイパーパラメータ\n",
    "1. モデル\n",
    "\n",
    "### 探索のサイクル\n",
    "\n",
    "以下のステップのサイクルを繰り返し、正確性の高い予測のためのモデルを探索します。\n",
    "\n",
    "1. 特徴の設計\n",
    "1. データの加工\n",
    "1. 類似度関数の設計\n",
    "1. 学習アルゴリズムの選択\n",
    "1. ハイパーパラメータの最適化\n",
    "1. モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovtm_E5WNWN_"
   },
   "source": [
    "## 著者当てゲーム\n",
    "短編小説のテキストからその著者を当てるゲームを通して、 機械学習における探索のサイクルを体験しましょう。その過程で、機械学習で用いられる基本的な概念などについても学べるはずです。\n",
    "\n",
    "### 著者当てゲームで使うデータについて\n",
    "\n",
    "今回の著者当てゲームでは[青空文庫](https://www.aozora.gr.jp)からテキストデータをダウンロードして利用します。\n",
    "> 青空文庫には15万件を超える作品が収録されているが、\n",
    "そのいずれも、著作権が消滅しているか、著作者から許諾が得られている作品である。\n",
    "\n",
    "また、今回は明治時代の文豪である\n",
    "芥川龍之介（1892年 - 1927年）と菊池寛（1888年 - 1948年)を取り上げます。\n",
    "二人の作品の著作権は消滅しています。\n",
    "> 二人は、同時代の語彙を共有していて、また、共に短編作品が多いことから、\n",
    "同じ条件で比較がしやすい。\n",
    "> 蛇足であるが、菊池寛は芥川賞設立の発起人のひとりである。\n",
    "\n",
    "芥川龍之介の作品からは、以下の20編を学習用のデータとして利用します。\n",
    "\n",
    "> 羅生門、妖婆、藪の中、貉、鼻、歯車、トロッコ、杜子春、俊寛、侏儒の言葉、邪宗門、将軍、死後、アグニの神、或る日の大石内蔵助、おぎん、河童、煙管、蜘蛛の糸\n",
    "\n",
    "菊池寛についても、同数の20編を選びました。\n",
    "\n",
    "> 姉川の戦い、ある恋の話、入れ札、M公爵と写真師、屋上の狂人、恩讐の彼方に、女強盗、恩を返す話、義民甚平、勲章を貰う話、極楽、出世、勝負事、大力の物語、藤十郎の恋、ある抗議書、身投げ救助業、無名作家の日記、若杉裁判長、奉行と人相学\n",
    "\n",
    "<!-- \n",
    "dataフォルダに青空文庫からダウンロードした上記40編の短編小説のテキストファイルを保存してあります。\n",
    "\n",
    "(＊dataフォルダの導入がうまくいかない場合は、以下のデータダウンロードのセルを実行することで、この先のコードも問題なく実行することができます。)\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uj-Layv1Jyk"
   },
   "source": [
    "### テキストデータの確認\n",
    "青空文庫からダウンロードしたデータは、dataフォルダにテキストファイルとして保存されています。\n",
    "\n",
    "data/rashomon.txtは「羅生門」の全文のテキストファイルです。\n",
    "data/rashomon.txtの全文を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1679962182512,
     "user": {
      "displayName": "大豆生田幹",
      "userId": "17706619674069057736"
     },
     "user_tz": -540
    },
    "id": "WBmviMRJc9fZ",
    "outputId": "c35b6f52-8680-4220-ea0f-fcaa8449558a"
   },
   "outputs": [],
   "source": [
    "open(\"data/rashomon.txt\", \"r\", encoding = \"shift-jis\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoqoqH8q3nN_"
   },
   "source": [
    "同様にdata/ahen.txtの全文を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1679962182512,
     "user": {
      "displayName": "大豆生田幹",
      "userId": "17706619674069057736"
     },
     "user_tz": -540
    },
    "id": "iUtj9PSv1c7D",
    "outputId": "18d6c8a5-e72c-417c-dab2-bb703ab51bbe"
   },
   "outputs": [],
   "source": [
    "open(\"data/ahen.txt\", \"r\", encoding = \"shift-jis\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSgPOV1bNhe4"
   },
   "source": [
    "## 2.2 機械学習における探索のサイクル\n",
    "正確性の高いモデルを見つけるために以下のステップを繰り返します。ここでは簡単、探索のサイクルについて紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLnq4Zz0NQS-"
   },
   "source": [
    "### 2.2.1 特徴設計\n",
    "データを分析する目的に照らして、注目する特徴を定めるステップです。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrOZYGdqNmur"
   },
   "source": [
    "### 2.2.2 データの加工\n",
    "データから特徴を抽出し、機械学習の処理に適した形式に整形するステップです。\n",
    "また、特徴の欠損値や外れ値などを処理したり、特徴値のスケールをそろえるための正規化処理なども本ステップで行います。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx1ft_rmNvcm"
   },
   "source": [
    "### 2.2.3 類似度関数の設計\n",
    "データの類似度を定量的に計算する類似度関数を決めるステップです。類似度関数を決めることは、類似性を定義づけることになるので、非常に重要なステップとなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__jzdSahN1eg"
   },
   "source": [
    "### 2.2.4 学習アルゴリズムの選択とハイパーパラメータ最適化\n",
    "データ分析の目的や選択した類似度関数に照らして、学習アルゴリズムを定めます。\n",
    "また、学習アルゴリズムは、事前に人間が定めておくべきハイパーパラメータを含むことがあります。\n",
    "最適なハイパーパラメータの値もこのステップで探索します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEmVEIT2N9Yt"
   },
   "source": [
    "### 2.2.5 モデル評価\n",
    "訓練データを学習アルゴリズムに入力すると、予測のためのモデルを得ることができます。作成したモデルに対してテストデータを入力し、予測値を計算し、答え合わせを行うことでモデルの性能を評価するステップです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kx12hYQlOCaP"
   },
   "source": [
    "### 2.2.6 スパイラルアップ\n",
    "以上のステップを性能の良いモデルが得られるまで繰り返し探索を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjE2nAg2OLAp"
   },
   "source": [
    "## 2.3 特徴設計\n",
    "ここでは「著者判定を行うために、与えられたテキストのどんな特徴に注目すべきか」を検討します。\n",
    "\n",
    "今回取り扱う生データはテキストであり、1章の例で使用した「ワイン価格のデータセット」のような「特徴を整理した表形式」のデータではありません。\n",
    "\n",
    "コンピュータにとってテキストは文字の羅列であり、それ以上の意味を持ちません。\n",
    "そのため、私たちが「著者の文体の違いを表現できるような特徴」を設計し テキストから抽出する必要があります。今回は以下の仮設に基づき、特徴を定めます。\n",
    "\n",
    "---\n",
    "<font color= \"red\">**文体は自立語である名詞・形容詞・動詞・副詞の分布によって特徴づけられる**</font>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYnu74swOPIZ"
   },
   "source": [
    "## 2.4 データの加工\n",
    "ここでは上記の仮説に従って、テキストデータから**特徴**を抽出します。\n",
    "\n",
    "具体的には、テキストに現れる自立語（名詞・形容詞・動詞・副詞）の全単語について出現回数を求め、\n",
    "表形式にまとめます。\n",
    "一つの作品について、作品中に現れる各自立語の個数が、この作品の特徴となります。\n",
    "\n",
    "実は40作品には16,307個の自立語が現れますので、\n",
    "各作品は、それぞれの自立語の出現回数である16,307個の数字の並び（**ベクトル**）によって特徴付けられます。\n",
    "\n",
    "実際に以下の手順に従って特徴抽出を行いましょう。\n",
    "\n",
    "1. 原文テキストの抽出\\\n",
    "テキストデータから余分な要素を取り除き**原文テキストを復元**します。\n",
    "1. 形態素解析\\\n",
    "作品毎に形態素解析を行うことでテキストを単語に分解します。\n",
    "2. 名詞・形容詞・動詞・副詞の抽出\n",
    "3. 名詞・形容詞・動詞・副詞の数え上げ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJ3QQ_OPMnVj"
   },
   "source": [
    "---\n",
    "### 1.原文テキストの抽出\n",
    "まずステップ1では、原文テキストの抽出を行います。\n",
    "\n",
    "\n",
    "青空文庫からダウンロードしたテキストファイルには、原文テキストにはない要素が含まれています。\n",
    "\n",
    "```\n",
    "\\u3000 ある日の暮方の事である。一人の下人《げにん》が、 羅生門《らしょうもん》の下で雨やみを待っていた。\\n\\u3000 広い門の下には、この男のほかに誰もいない。ただ、所々|丹塗《にぬり》の剥《は》げた、大きな円柱《まるばしら》に、 蟋蟀《きりぎりす》が一匹とまっている。\n",
    "...(中略)... \n",
    "  下人はとうとう、老婆の腕をつかんで、無理にそこへ※［＃「てへん＋丑」、第4水準2-12-93］《ね》じ倒した。丁度、鶏《にわとり》の脚のような、骨と皮ばかりの腕である。\\n「何をしていた。云え。云わぬと、これだぞよ。」\n",
    "  \\n\\u3000下人は、老婆をつき放すと、いきなり、太刀の鞘《さや》を払って、白い鋼《はがね》の色をその眼の前へつきつけた。\n",
    "...(中略)... \n",
    "そうし て、そこから、短い白髪《しらが》を倒《さかさま》にして、 門の下を覗きこんだ。外には、ただ、黒洞々《こくとうとう》 たる夜があるばかりである。\\n\\u3000 下人の行方《ゆくえ》 は、誰も知らない。\n",
    "```\n",
    "\n",
    ">- ユニコードエスケープは、UTF-8やUTF-16で符号化された文字を 直接指定する方法で、例えば、\\u3000 は全角のスペースを表します。\n",
    ">- \\nは改行を表す制御文字です。\n",
    ">- 《げにん》などの漢字の読みの表示は、青空文庫で決めている書式です。\n",
    ">- JIS水準が高い漢字は、注釈記号を使って表示されます。\n",
    "例えば、※\\[#「てへん+丑」、第 4 水準 2-12-93\\]などです。\n",
    ">- 注釈や漢文の返り点なども注釈記号を用いて記述されます。注釈記号は青空文庫で決めている書式です。\n",
    "\n",
    "これらの要素は形態素解析の結果に影響を及ぼす可能性のあるものがあります。\n",
    "\n",
    ">- ユニコードエスケープと制御記号は標準で定められた書式で、形態素解析に影響を与えないので、ここでは除去しません。\n",
    ">- ルビや注釈は青空文庫固有の書式で記述されているため形態素解析を実行する上で障害となる可能性があります。JIS水準が高い漢字を含む語は読みで置き換え、その他の注釈とルビは削除します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 例1\n",
    "\n",
    "> 下人はとうとう、老婆の腕をつかんで、無理にそこへ※［＃「てへん＋丑」、第4水準2-12-93］《ね》じ倒した。丁度、鶏《にわとり》の脚のような、骨と皮ばかりの腕である。\n",
    "「何をしていた。云え。云わぬと、これだぞよ。」\n",
    "　下人は、老婆をつき放すと、いきなり、太刀の鞘《さや》を払って、白い鋼《はがね》の色をその眼の前へつきつけた。\n",
    "\n",
    "> 下人はとうとう、老婆の腕をつかんで、無理にそこへねじ倒した。丁度、鶏の脚のような、骨と皮ばかりの腕である。\n",
    "「何をしていた。云え。云わぬと、これだぞよ。」\n",
    "　下人は、老婆をつき放すと、いきなり、太刀の鞘を払って、白い鋼の色をその眼の前へつきつけた。\n",
    " \n",
    "#### 例2\n",
    "\n",
    "> 僕はこの頃漫然と兪※［＃「木＋越」、第3水準1-86-11］《ゆゑつ》の「右台仙館筆記《うたいせんくわんひつき》」を読んでゐるうちにかう云ふ俗伝は支那人の中にもあつたと云ふことを発見した。それは同書の中に掲げた「賈慎庵《かしんあん》」の話に出合つたからである。\n",
    "　賈慎庵は何でも乾隆《けんりゆう》の末の老諸生の一人だつたと云ふことである。それが或夜の夢の中に大きい役所らしい家の前へ行つた。家は重門｜尽《ことごと》く掩《おほ》ひ、闃《げき》としてどこにも人かげは見えない。「正に徘［＃「徘」は底本では「俳」］徊《はいくわい》の間、俄《には》かに数人あり、一婦を擁して遠きより来り、この門の外に至る。\n",
    " \n",
    "> 僕はこの頃漫然とゆゑつの「右台仙館筆記」を読んでゐるうちにかう云ふ俗伝は支那人の中にもあつたと云ふことを発見した。それは同書の中に掲げた「賈慎庵」の話に出合つたからである。\n",
    "　賈慎庵は何でも乾隆の末の老諸生の一人だつたと云ふことである。それが或夜の夢の中に大きい役所らしい家の前へ行つた。家は重門｜尽く掩ひ、闃としてどこにも人かげは見えない。「正に徘徊の間、俄かに数人あり、一婦を擁して遠きより来り、この門の外に至る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYqkp7vKMWyF"
   },
   "source": [
    "### 2.形態素解析\n",
    "次にステップ2では、形態素解析を行います。\n",
    "\n",
    "- 文字列を形態素（単語）に分解\n",
    "- 各形態素の品詞を特定\n",
    "- 活用形を標準形（終止形）に変換\n",
    "\n",
    "> 文中で意味をもつ文字の並びの最小単位を、自然言語処理では**形態素**と呼ぶ。\n",
    "単純のため単語と同義と考えてもよいが、\n",
    "複数の単語が結合して別の単語を構成することがある一方、\n",
    "形態素はそれ以上分解できない最小の単位を表す。\n",
    "テキストの文法構造を明らかにするためには、\n",
    "まず、単なる記号の列であるテキストを、形態素の集まりに整理し、\n",
    "それぞれの形態素に対して、その品詞と用法を特定することが必要である。\n",
    "このような処理のことを、**形態素解析**と呼ぶ。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oPehoY68o5S"
   },
   "source": [
    "MeCabという形態素解析のライブラリーを利用した時の形態素解析の例を示します。\n",
    "\n",
    "**原文**\n",
    "> 一人の下人が、羅生門の下で雨やみを待っていた。\n",
    "\n",
    "**形態素解析の結果**\n",
    "> *:BOS/EOS:*   一:名詞:数   人:名詞:接尾   の:助詞:連体化   下人:名詞:一般   が:助詞:格助詞   、:記号:読点   羅生門:名詞:固有名詞   の:助詞:連体化   下:名詞:一般   で:助詞:格助詞   雨:名詞:一般   やみ:名詞:一般   を:助詞:格助詞   待つ:動詞:自立   て:助詞:接続助詞   いる:動詞:非自立   た:助動詞:*   。:記号:句点   *:BOS/EOS:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LM9rfqDzP3of"
   },
   "source": [
    "### 3. 自立語（形容詞・動詞・名詞・副詞）の抽出\n",
    "\n",
    "ステップ3では、形態素解析の結果から、形容詞、動詞、名詞、副詞のみを残して、\n",
    "残りを除去します。\n",
    "\n",
    "**原文**\n",
    "> 一人の下人が、羅生門の下で雨やみを待っていた。\n",
    "\n",
    "**自立語抽出の結果**\n",
    "> '一:名詞:数', '人:名詞:接尾', '下人:名詞:一般', '羅生門:名詞:固有名詞', '下:名詞:一般', '雨:名詞:一般', 'やみ:名詞:一般', '待つ:動詞:自立', 'いる:動詞:非自立']\n",
    "一:名詞:数   人:名詞:接尾   下人:名詞:一般   羅生門:名詞:固有名詞   下:名詞:一般   雨:名詞:一般   やみ:名詞:一般   待つ:動詞:自立   いる:動詞:非自立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olOLpDGdRy4l"
   },
   "source": [
    "### 4. 自立語（形容詞・動詞・名詞・副詞）の数え上げ\n",
    "\n",
    "ステップ3までで、任意のテキストのルビと注釈を削除し、全ての形態素を含むリストを作成しました。\n",
    "ステップ4では、各形態素がテキスト中に何回出現するかを数え上げます。\n",
    "\n",
    "**原文**\n",
    "> 私の兄は私より背が高いです。あなたの弟は私よりも背が高いですか?\n",
    "\n",
    "**自立語抽出の結果**\n",
    "> 私:名詞:代名詞   兄:名詞:一般   私:名詞:代名詞   背:名詞:一般   高い:形容詞:自立   あなた:名詞:代名詞   弟:名詞:一般   私:名詞:代名詞   背:名詞:一般   高い:形容詞:自立\n",
    "\n",
    "**自立語数え上げの結果**\n",
    "> '私:名詞:代名詞': 3, '背:名詞:一般': 2, '高い:形容詞:自立': 2, '兄:名詞:一般': 1, 'あなた:名詞:代名詞': 1, '弟:名詞:一般': 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QzHgkiUgsO3"
   },
   "source": [
    "### 40作品に対して特徴を抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fx5tC_GtVSw5"
   },
   "source": [
    "以上の4つのステップに従い、\n",
    "ダウンロードした芥川龍之介・菊池寛の各作品から特徴を抽出した結果を保存したファイルを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akutagawa_name = np.load('data/akutagawa_name.npy', allow_pickle=True)\n",
    "kikuchi_name = np.load('data/kikuchi_name.npy', allow_pickle=True)\n",
    "hgram = np.load('data/hgram.npy', allow_pickle=True)\n",
    "words = np.load('data/words.npy', allow_pickle=True)\n",
    "print('芥川龍之介の作品は以下の20編')\n",
    "print(' '.join(akutagawa_name))\n",
    "print('\\n菊池寛の作品は以下の20編')\n",
    "print(' '.join(kikuchi_name))\n",
    "print('\\n40編の作品に現れる語の総数は{}語'.format(len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各作品の特徴ベクトルの一部を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNFL5dLlc24l",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# (表形式のデータの作成)\n",
    "columns = ['する:動詞:自立', 'いる:動詞:非自立', 'の:名詞:非自立', \n",
    "           '事:名詞:非自立',\n",
    "           '云う:動詞:自立',\n",
    "           '老婆:名詞:一般',\n",
    "           'よう:名詞:非自立',\n",
    "           'なる:動詞:自立']\n",
    "\n",
    "def count(n, w):\n",
    "    if w in hgram[n]:\n",
    "        return hgram[n][w]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "body = []\n",
    "for n in range(20):\n",
    "    temp = [count(n, w) for w in columns]\n",
    "    temp.append('芥川')\n",
    "    body.append(temp)\n",
    "for n in range(20):\n",
    "    temp = [count(n+20, w) for w in columns]\n",
    "    temp.append('菊池')\n",
    "    body.append(temp)\n",
    "\n",
    "df = pd.DataFrame(body)\n",
    "columns.append('著者')\n",
    "df.columns = columns\n",
    "df.index = np.hstack([akutagawa_name, kikuchi_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlHCU2Jzc_zU"
   },
   "source": [
    "各作品に対して、8個の数値が与えられています。\n",
    "実際には、各作品の特徴は16,307個の数値の並びですので、\n",
    "上の表は作品の特徴のごくごく一部を表示しているにすぎません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6em9gEaOYpf"
   },
   "source": [
    "## 2.5 類似度関数の設計\n",
    "まず、作品の特徴の分布、即ち、作品中に現れる名詞・形容詞・動詞・副詞の出現頻度の分布を作品ごとに表示し、観察します。\n",
    "その上で、私たち人間が特徴の分布を眺めていても、芥川龍之介の作品と菊池寛の作品を分類するための規則やパターンを見出すことが難しいことを体感してみます。\n",
    "\n",
    "始めに、「羅生門(芥川)」と「姉川の戦い(菊池)」について、2.4節で得られた形態素の分布を比較してみましょう。(試しに以下の8項目の特徴で比較)\n",
    "1. 'する:動詞:自立'\n",
    "1. 'いる:動詞:非自立'\n",
    "1. 'の:名詞:非自立'\n",
    "1. '事:名詞:非自立'\n",
    "1. '云う:動詞:自立'\n",
    "1. '老婆:名詞:一般'\n",
    "1. 'よう:名詞:非自立'\n",
    "1. 'なる:動詞:自立'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CFyIaUowJgR"
   },
   "outputs": [],
   "source": [
    "pip install japanize-matplotlib # 日本語版matplotlibのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJ6YgWe3jl4W"
   },
   "outputs": [],
   "source": [
    "# 前記の8項目の特徴に関して、「羅生門」と「姉川の戦い」の分布を比較\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "df_wo_author = df[df.columns[:-1]]\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=[15,6])\n",
    "fig1 = df_wo_author.loc['羅生門'].plot.bar(title='羅生門（芥川龍之介）', ax=axes[0], fontsize=16)\n",
    "fig1.axes.title.set_size(24)\n",
    "fig2 = df_wo_author.loc['姉川の戦い'].plot.bar(title='姉川の戦い（菊池寛）', ax=axes[1], fontsize=16)\n",
    "fig2.axes.title.set_size(24)\n",
    "\n",
    "axes[0].set_ylim([0,160])\n",
    "axes[1].set_ylim([0,160])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmAhow4TkHbw"
   },
   "source": [
    "同じ8項目の特徴に関して、全作品の分布を比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSV8ioN9kNXz"
   },
   "outputs": [],
   "source": [
    " # 8項目の特徴の分布を全作品で比較\n",
    "_, axes = plt.subplots(10, 4, figsize=[20,30])\n",
    "# _, axes = plt.subplots(8, 5, figsize=[20,25])\n",
    "for n in range(40):\n",
    "    title = df.index[n]\n",
    "    df_wo_author.loc[title].plot.bar(title=title+('（芥川）' if n < 20 else '（菊池）'), \n",
    "                                     ax=axes[int(n/4), n%4],\n",
    "                                     xticks=[]\n",
    "                                    )\n",
    "    axes[int(n/4), n%4].set_ylim([0, 400])\n",
    "    axes[int(n/4), n%4].xaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1g952nrkRDN"
   },
   "source": [
    "作品ごとに大きくばらついていることが分かると思います。\n",
    "この分布を眺めて、芥川の作品に共通に見られるパターン、\n",
    "菊池の作品に共通に見られるパターンで、\n",
    "芥川の作品と菊池の作品を区別できるものを見つけることはできるでしょうか？\n",
    "\n",
    "8個の特徴だけでは不十分なので、全16301項目の特徴に関して、同じように比較をしましょう。\n",
    "まず、「羅生門(芥川)」と「姉川の戦い(菊池)」の分布を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kpsvt50kQgQ"
   },
   "outputs": [],
   "source": [
    " # 「羅生門(芥川)」と「姉川の戦い(菊池)」の分布の比較\n",
    "import numpy as np\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=[15,5])\n",
    "\n",
    "y = [count(0, w) for w in words]\n",
    "axes[0].plot(range(len(words)), y)\n",
    "axes[0].set_title('羅生門（芥川龍之介）', fontsize=24)\n",
    "axes[0].set_ylim([0, 160])\n",
    "axes[0].xaxis.set_visible(False)\n",
    "axes[0].set_yticklabels(np.arange(0, 170, 20), fontsize=16)\n",
    "\n",
    "y = [count(20, w) for w in words]\n",
    "axes[1].plot(range(len(words)), y)\n",
    "axes[1].set_title('姉川の戦い（菊池寛）', fontsize=24)\n",
    "axes[1].set_ylim([0, 160])\n",
    "axes[1].xaxis.set_visible(False)\n",
    "axes[1].set_yticklabels(np.arange(0, 170, 20), fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsDor7opk13z"
   },
   "source": [
    "更に、全16301項目の特徴に関して、全作品の分布を比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HfVEuA0Ok_Q5"
   },
   "outputs": [],
   "source": [
    " # 全作品の全単語の分布の比較(2分くらい実行時間がかかります)\n",
    "_, axes = plt.subplots(10, 4, figsize=[20,30])\n",
    "for n in range(40):\n",
    "    title = df.index[n]\n",
    "    y = [count(n, w) for w in words]\n",
    "    ax = axes[int(n/4), n%4]\n",
    "    ax.plot(range(len(words)), y)\n",
    "    ax.set_ylim([0, 400])\n",
    "    ax.set_title(title+('（芥川）' if n < 20 else '（菊池）'), fontsize=20)\n",
    "    ax.xaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65CvGrLRk9PE"
   },
   "source": [
    "人の目で上図を観察して、芥川龍之介の作品と菊池寛の作品を分類するための規則やパターンを見出すことは難しいことがわかると思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tFi9rnamb2L"
   },
   "source": [
    "分類の目標は同じ著者の作品間の分布の違いは受容し、違う著者の作品間の分布の違いを検出することです。私達はこの複雑な問題を解くために、適切な類似度関数を設計する必要があります。\n",
    "\n",
    "> 類似度関数は2変数実関数$\\sigma(x, y)$であり、厳密には以下のように定義されています。\n",
    ">\n",
    "> | 関数 | 定義 |\n",
    "> |:----|:----|\n",
    "> |**類似度関数** | $x$と$y$が似ているほど、大きな値を返す |\n",
    "> |**非類似度関数** | $x$と$y$が似ているほど、小さな値を返す |\n",
    ">\n",
    "> 便宜上、これらを区別せず類似度関数と呼ぶこととします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz5mMc3Qn8mP"
   },
   "source": [
    "#### ユークリッド距離（$L^2$ノルム）\n",
    "$L^2$ノルムは、多変量解析・統計で基本とするベクトルの長さの定義です。\n",
    "\n",
    "データは16301次元のベクトルとして表現されるので、ユークリッド距離を(非)類似度関数として利用してみることとします。\n",
    "\n",
    "一つのデータを16301次元のベクトル空間の点と考えて、二つのデータがどの程度似ているかは二点間の距離を指標にして考えます。二点間の距離は二点を結ぶベクトルの長さで定義します。\n",
    "\n",
    "$$\n",
    "d_{L^2}\\left((v_1, \\dots, v_{16301}), (w_1, \\dots, w_{16301})\\right) \n",
    "= \\sqrt{\\sum_{i=1}^{16301} (v_i - w_i)^2} \n",
    "$$\n",
    "\n",
    "試しに、芥川龍之介の「羅生門」と菊池寛の「姉川の戦い」のユークリッド距離を計算してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CSxoMQY-qEm7"
   },
   "outputs": [],
   "source": [
    "# 「羅生門」と「姉川の戦い」のユークリッド距離\n",
    "def dl2(dictx, dicty):\n",
    "    sq = 0\n",
    "    for key in set(dictx.keys()) | set(dicty.keys()):\n",
    "        x, y = 0, 0\n",
    "        if key in dictx: \n",
    "            x = dictx[key]\n",
    "        if key in dicty:\n",
    "            y = dicty[key]\n",
    "        sq += (x - y)**2\n",
    "    return math.sqrt(sq)\n",
    "        \n",
    "print('「羅生門」と「姉川の戦い」のユークリッド距離 = ', dl2(hgram[0], hgram[20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWL8S5sHqS6Z"
   },
   "source": [
    "#### 距離行列の計算\n",
    "全てのデータ（作品）間の距離を計算し、$40 \\times 40$の行列にまとめたものを、\n",
    "**距離行列**と呼びます。\n",
    "\n",
    "> $i$番目と$j$番目のデータの距離が、距離行列の$i$行・$j$列の値で与えられます。\n",
    "\n",
    "距離行列は類似度関数として距離関数を使用した場合の類似度行列です。\n",
    "- 類似度行列は全ての訓練データのペアの間の類似度を含んでいます。\n",
    "- 類似度行列は**対称行列**です。即ち、左上から右下への対角線を軸として、値は対象になります。\n",
    "- 類似度関数として距離関数を用いた場合、類似度行列の対角成分は全て0となります。\n",
    "\n",
    "以下のセルでは、$40\\times 40$の距離行列を計算した後、\n",
    "先頭の5行・5列のみを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sr2kFXkeqjze"
   },
   "outputs": [],
   "source": [
    " # 距離行列の作成\n",
    "temp = [] \n",
    "for dictx in hgram:\n",
    "    temp.append(list(map(lambda dicty: dl2(dictx, dicty), hgram)))\n",
    "dl2_matrix = np.array(temp) # 距離の行列\n",
    "\n",
    "print(dl2_matrix[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nm6B1WvwOihW"
   },
   "source": [
    "## 2.6 学習アルゴリズムの選択\n",
    "ここでは、著者判定の学習アルゴリズムとして、\n",
    "距離に基づく分類アルゴリズムとしては非常に一般的な\n",
    "**k-NNアルゴリズム**を指定します。\n",
    "\n",
    "k-NNアルゴリズムについて理解したのち、\n",
    "k-NNアルゴリズムの有効性を(参考程度に)事前に確認する手段として**次元圧縮によるデータの可視化**を行います。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBfSrBQzOnjq"
   },
   "source": [
    "### 2.6.1 k-NN アルゴリズム\n",
    "---\n",
    "\n",
    "**テストデータに最も距離が近い$k$個の訓練データを探索し、これらの訓練データのラ\n",
    "ベルの多数決により、ラベルを予測する**\n",
    "\n",
    "---\n",
    "\n",
    "> k はハイパーパラメータと呼ばれ、k-NN アルゴリズムを訓練データに 適用する前に決定しておく必要があります。k の値によって、k-NN アルゴリズムの結果が異なってくるので、最適な kの値を選ぶことは重要です。\n",
    ">\n",
    "> 下の例では、k = 3 ではテストデータのクラスは「芥川」、k = 5 ではテストデータのクラスは「菊池」と分類されます。最適な k を決定する方法については、次の節で触れます。\n",
    "\n",
    "まずはk-NNアルゴリズムについて、直感的に理解していきましょう。ひとまず、次のセルを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xSeiQQz_uJpP"
   },
   "outputs": [],
   "source": [
    " # これはk-NNアルゴリズムを説明するための図(これまでに作成した40作品のデータとは全く関係ないことに注意)\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.scatter([-1,.5,.6,.8,2], [2,-.5,.3,1.8,-1], c='black', \n",
    "            marker='+', s=100, label='芥川')\n",
    "plt.scatter([-2,-1,0,-.8,1], [-2,0,1.5,-.8,-1.6], c='black', \n",
    "            marker='o', label='菊池')\n",
    "plt.scatter([0], [0], c='black', marker='s', label='テスト')\n",
    "plt.plot([np.cos(t) for t in np.linspace(0, 2*np.pi, 50)],\n",
    "         [np.sin(t) for t in np.linspace(0, 2*np.pi, 50)],\n",
    "         label='$k = 3$', c='black'\n",
    "        )\n",
    "plt.plot([1.5*np.cos(t) for t in np.linspace(0, 2*np.pi, 50)],\n",
    "         [1.5*np.sin(t) for t in np.linspace(0, 2*np.pi, 50)],\n",
    "         label='$k = 5$', c='black', linestyle='dashed'\n",
    "        )\n",
    "plt.grid()\n",
    "plt.legend(fontsize=14, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_e1LPLM2uKdP"
   },
   "source": [
    "■はテストデータで、●と**＋**は訓練データで、それぞれ菊池と芥川の作品を表しています。\n",
    "- $k=3$ならば、テストデータから距離が小さい3個の訓練データを見つけます(実線円)。●が一つ、**＋**が二つなので、多数決によって■を芥川の作品と予測します。\n",
    "- $k=5$ならば、テストデータから距離が小さい5個の訓練データを見つけます(点線円)。今回は●が三つ、**＋**が二つなので、多数決によって■を菊池の作品と予測します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD9gk2RLOwyn"
   },
   "source": [
    "### 2.6.2 k-NN アルゴリズムの適性\n",
    "\n",
    "k-NNのアルゴリズの適性を以下の例を用いて解説します。\n",
    "*   分布が分離していてk-NNが適している例\n",
    "*   分布が重なっていてk-NNが適さない例\n",
    "*   これらの中間の例\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xI4AYlIwv74J"
   },
   "outputs": [],
   "source": [
    " # 基準の分布\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "n = 100\n",
    "x1 = np.random.randn(n)\n",
    "y1 = np.random.randn(n)\n",
    "dx2 = np.random.randn(n)\n",
    "y2 = np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_7CYYv5Lv-dP"
   },
   "outputs": [],
   "source": [
    " # 分布が分離していてk-NNが適している例\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "a = 10\n",
    "plt.scatter(x1, y1, color='black', marker='+', s=100)\n",
    "x2 = np.ones(n)*a + dx2\n",
    "plt.scatter(x2, y2, color='black', marker='o')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eckdv1atTCSd"
   },
   "source": [
    "分布が分離しているケースでは、k-NNは1に近い確率で予測を的中させることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OoWZ8dFlwDgs"
   },
   "outputs": [],
   "source": [
    " # 分布が重なっていてk-NNが適さない例\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "a = 0\n",
    "plt.scatter(x1, y1, color='black', marker='+', s=100)\n",
    "x2 = np.ones(n)*a + dx2\n",
    "plt.scatter(x2, y2, color='black', marker='o', alpha=0.5)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtJ-p7wETaM5"
   },
   "source": [
    "このように、分布が同一であるケースでは、k-NNは原理的に1/2の確率でしか予測を的中させることができません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "75fJ6rt4wKvn"
   },
   "outputs": [],
   "source": [
    " # 中間の例\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 5)\n",
    "a = 3\n",
    "plt.scatter(x1, y1, color='black', marker='+', s=100 )\n",
    "x2 = np.ones(n)*a + dx2\n",
    "plt.scatter(x2, y2, color='black', marker='o', alpha=0.5)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIw2WB79URVa"
   },
   "source": [
    "二つの分布が交差する領域では、k-NNの予測の的中率は1/2に近いと想像できますので、全体の的中率は的中率は1/2と1の間になる筈です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbXh1CZYO7V3"
   },
   "source": [
    "### 2.6.3 次元圧縮による可視化\n",
    "k-NNアルゴリズムの適性を(参考程度に)見積もるために、著者判定のための特徴ベクトルに関しても2.6.2節で行ったようなデータの分布を確認したいところですが、ベクトルの次元が16301次元であるため、可視化することができません。\n",
    "\n",
    "そこで、**次元削減**と呼ばれる手法を用いて、16301次元を3次元に圧縮して可視化してみましょう。\n",
    "\n",
    "先に計算した作品間の距離を「できるだけ」保存するように、三次元空間にプロットします。\n",
    "まず、40編の作品のそれぞれに対して、\n",
    "$x$座標、$y$座標、$z$座標の3つの値を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "oi7XJhCEyzU5"
   },
   "outputs": [],
   "source": [
    "# MDSで16301次元のベクトル達をを3次元に無理やり圧縮\n",
    "mds = manifold.MDS(n_components=3, dissimilarity=\"precomputed\", random_state=6)\n",
    "pos = mds.fit_transform(dl2_matrix)\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1jZ5jlazOJo"
   },
   "source": [
    "MDSで三次元に投影した結果を可視化してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ui54TYnG242r"
   },
   "outputs": [],
   "source": [
    " # MDSで3次元に圧縮\n",
    "l1 = len(akutagawa_name)\n",
    "l2 = len(kikuchi_name)\n",
    "\n",
    "fig = go.Figure(\n",
    "    layout=go.Layout(\n",
    "    title=\"ユークリッド距離に基づくデータの分布（MDSによる次元圧縮）\" ,\n",
    "    showlegend=True,\n",
    "    legend=dict(x=0.7, y=0.99, xanchor='left', yanchor='top', font=dict(size=16))\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "        x = pos[0: l1,0], y = pos[0: l1,1], z = pos[0: l1,2],\n",
    "        mode = 'markers',\n",
    "        marker = dict(symbol='cross', color='black', size=5, \n",
    "                      line=dict(width=0), opacity=1 ),\n",
    "        name = '芥川'\n",
    "        )\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "        x = pos[l1: l1+l2, 0], y = pos[l1: l1+l2, 1], z = pos[l1: l1+l2, 2],\n",
    "        mode = 'markers',\n",
    "        marker = dict(symbol='circle', color='black', size=5, \n",
    "                      line=dict(width=0), opacity=1),\n",
    "        name = '菊池'\n",
    "        )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI7IDno4n-Ia"
   },
   "source": [
    "グラフをドラッグして、希望の方向から分布を観察することができます。\n",
    "\n",
    "芥川の作品のプロットと菊池の作品のプロットは分かれているように見えますが、分布は隣接しているため、k-NNで予測を行った場合の正解率は高くならない懸念もあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVjyq6VEPIJn"
   },
   "source": [
    "## 2.7 ハイパーパラメータの最適化\n",
    "ここでは、学習アルゴリズムとして採用したk-NNアルゴリズムについて、ハイパーパラメータである$k$の最適な値をグリッド探索によって決定します。\\\n",
    "その過程で、限りあるデータを上手く活用することで予測の正確性と正解率の信頼性を高める「交差検証」と、モデルを評価する上で重要な役割を果たす「混同行列」についての理解を深めます。\n",
    "\n",
    "**$k$を決定する方針**\n",
    "1. $k$の値を1から10まで変えて学習と予測を実行\n",
    "\n",
    "1. 各$k$の値に対して予測の正解率（正解予測数の全予測数に対する比率）を計算\n",
    "\n",
    "1. 最も高い正解率を出した$k$を最適値として採用\n",
    "\n",
    "最適なハイパーパラメータを決定するに当たり、\n",
    "一定の範囲において総当たりで予測性能を評価し、\n",
    "最も良好な予測性能を示した値を最適値とする探索手法を**グリッド探索**と呼びます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40個のデータを**訓練データ**として利用して学習を実行し、\n",
    "同じ40個のデータを**テストデータ**として予測を行ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mxV2MjwJ0_i9"
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータの値と正解率の関係を得る\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "l1 = len(akutagawa_name)\n",
    "l2 = len(kikuchi_name)\n",
    "labels = [0]*l1 + [1]*l2\n",
    "\n",
    "y = []\n",
    "for k in range(1, 11):\n",
    "    clf = KNeighborsClassifier(metric='precomputed', n_neighbors=k)\n",
    "    clf.fit(dl2_matrix, labels)\n",
    "    pred = clf.predict(dl2_matrix)\n",
    "    y.append(accuracy_score(labels, pred))\n",
    "\n",
    "# ハイパーパラメータの値と正解率の関係の可視化\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('$k$', fontsize=16)\n",
    "plt.ylabel('正解率', fontsize=16)\n",
    "plt.bar(range(1, 11), y)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解率は、$k = 1$の時に1.0、$k = 3$の時に0.9となり、\n",
    "一見うまくいっているように見えます。\n",
    "\n",
    "しかし、この一見よい結果は、**カンニング効果**、つまり、\n",
    "試験問題の答えを予め知っていたことによるものです。\n",
    "\n",
    "つまり、正確な予測性能の評価を行うためには、\n",
    "**訓練データと異なるテストデータで評価しなければならない**\n",
    "という原則があるのですが、\n",
    "この原則に従わなかったことから不適切に高い正解率が得られた訳です。\n",
    "\n",
    "利用できるデータ数に限りがあるとき、次のような問題が起こります。\n",
    "\n",
    "- 訓練データが少ないと、学習が十分に行われず、予測性能が低くなる\n",
    "- テストデータが少ないと、偶然により予測の分布が偏る可能性があり、評価の信頼性が低くなる\n",
    "\n",
    "例えば、40個あるデータを半分に割って、\n",
    "学習用に20個、テスト用に20個使うものとすると、\n",
    "訓練データ数・テストデータ数のどちらも不十分であり、\n",
    "適切な評価を行えない可能性が高いと考えられます。\n",
    "\n",
    "利用できるデータ数が少ないときには、**交差検証法**が有効です。\n",
    "交差検証法の詳細については、別の資料で説明しますが、\n",
    "以下では交差検証法により適切に計算された正解率を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mxV2MjwJ0_i9"
   },
   "outputs": [],
   "source": [
    " # ハイパーパラメータの値と正解率の関係を得る\n",
    "parameters = [{'metric': ['precomputed'], \n",
    "               'n_neighbors': list(range(1,11))}]\n",
    "clf = GridSearchCV(KNeighborsClassifier(), parameters, cv=5)\n",
    "clf.fit(dl2_matrix, labels)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "params = clf.cv_results_['params']\n",
    "mean_test_score = clf.cv_results_['mean_test_score']\n",
    "std_test_score = clf.cv_results_['std_test_score']\n",
    "for p, m, s in zip(params, mean_test_score, std_test_score):\n",
    "    print(f\"{m:.3f} (+/- {s/2:.3f}) for {p}\")\n",
    "    x.append(p['n_neighbors'])\n",
    "    y.append(m)\n",
    "\n",
    " # ハイパーパラメータの値と正解率の関係の可視化\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('$k$', fontsize=16)\n",
    "plt.ylabel('正解率', fontsize=16)\n",
    "plt.bar(x, y)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b62X8GG61oWS"
   },
   "source": [
    "正解率の一番高い$k$をハイパーパラメータの最適値とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UB5LR3p61yb0"
   },
   "outputs": [],
   "source": [
    " # kの最適値\n",
    "clf.best_estimator_.n_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBtis131Po8t"
   },
   "source": [
    "## 2.8 モデルの評価\n",
    "正解率の最大値を求めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AzU2eB3M2IMi"
   },
   "outputs": [],
   "source": [
    " # 正解率の最大値\n",
    "scores = model_selection.cross_val_score(clf.best_estimator_, X = dl2_matrix, y = labels, cv = 5)\n",
    "np.average(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJYFf5fa4xhF"
   },
   "source": [
    "正解率が低く、さらに探索をする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LFwIAxT07ueB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hzuw7RewQVAG"
   ],
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
