{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備\n",
    "## ライブラリのインストール\n",
    "Colaboratory環境で実行する場合は`japanaize_matplotlib`をインストールする必要があります。\n",
    "\n",
    "SageMaker環境で以下を実行する必要はありませんが、実行しても害はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: japanize_matplotlib in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from japanize_matplotlib) (3.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (3.0.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (1.22.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (8.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from matplotlib->japanize_matplotlib) (4.29.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yggdrasil/miniforge3/envs/python3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->japanize_matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b79J21iz8d4"
   },
   "source": [
    "## ライブラリのインポートとデータの読み込み\n",
    "\n",
    "この資料で使用するライブラリを一括してインポートし、必要なデータを読み込みます。\n",
    "\n",
    "SageMakerやColaboratoryの接続がタイムアウトした時は、\n",
    "以下のセルを再実行して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2511,
     "status": "ok",
     "timestamp": 1679962134584,
     "user": {
      "displayName": "大豆生田幹",
      "userId": "17706619674069057736"
     },
     "user_tz": -540
    },
    "id": "V6bMR59i0o5R",
    "outputId": "4010836c-2077-4cd4-96b3-9ffd5cd6b8b5"
   },
   "outputs": [],
   "source": [
    "#ライブラリーのインポート\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn import manifold\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import japanize_matplotlib\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "#データセットの読み出し\n",
    "akutagawa_name = np.load('data/akutagawa_name.npy', allow_pickle=True)\n",
    "kikuchi_name = np.load('data/kikuchi_name.npy', allow_pickle=True)\n",
    "hgram = np.load('data/hgram.npy', allow_pickle=True)\n",
    "words = np.load('data/words.npy', allow_pickle=True)\n",
    "print('芥川龍之介の作品は以下の20編')\n",
    "print(' '.join(akutagawa_name))\n",
    "print('\\n菊池寛の作品は以下の20編')\n",
    "print(' '.join(kikuchi_name))\n",
    "print('\\n40編の作品に現れる語の総数は{}語'.format(len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ARbvVHIPwdO"
   },
   "source": [
    "## 2.9 データの加工(第2ラウンド)\n",
    "これまでの方法で正解率が高くない原因を、データの加工という観点から考えてみます。\\\n",
    "まずはじめに、第1ラウンドで使用した加工済みの「歯車(芥川)」と「蜘蛛の糸(芥川)」の頻度分布を比較してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "I5QSJ8c-2UAu"
   },
   "outputs": [],
   "source": [
    " # 歯車(芥川)と蜘蛛の糸(芥川)の頻度分布の比較\n",
    "def count(n, w):\n",
    "    if w in hgram[n]:\n",
    "        return hgram[n][w]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=[15,5])\n",
    "\n",
    "y = [count(5, w) for w in words] # countはn(第一引数)番目の作品にwという単語は何回出現しているかを返す関数、wordsは40作品に出現するすべての単語を持つリスト。\n",
    "axes[0].plot(range(len(words)), y)\n",
    "axes[0].set_title('歯車', fontsize=20)\n",
    "axes[0].set_ylim([0, 160])\n",
    "axes[0].xaxis.set_visible(False)\n",
    "axes[0].set_yticklabels(range(0, 161, 20), fontsize=16)\n",
    "\n",
    "y = [count(19, w) for w in words] #5は歯車に、19は蜘蛛の糸に対応した番号\n",
    "axes[1].plot(range(len(words)), y)\n",
    "axes[1].set_title('蜘蛛の糸', fontsize=20)\n",
    "axes[1].set_ylim([0, 160])\n",
    "axes[1].xaxis.set_visible(False)\n",
    "axes[1].set_yticklabels(range(0, 161, 20), fontsize=16)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYWWdvE92WMS"
   },
   "source": [
    "共に芥川龍之介の作品ですが、分布の見た目は大きく異なっています。この相違の最大の原因は作品の長さにあり、芥川か菊池かを判断するための障害になりかねません。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "g_Ff5tXB2Vf-"
   },
   "outputs": [],
   "source": [
    " # 歯車の語数と蜘蛛の糸の語数の比較\n",
    "print(f'歯車の名詞・動詞・形容詞・副詞の語数は {sum(hgram[5].values())}')\n",
    "print(f'蜘蛛の糸の名詞・動詞・形容詞・副詞の語数は {sum(hgram[19].values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmpVZY7VNk19"
   },
   "source": [
    "実際、「歯車」に現れる名詞・動詞・形容詞・副詞の個数は、「蜘蛛の糸」のそれのそれの10倍以上であることが分かります。\n",
    "\n",
    "ここでは、正規化をすることで、複数種類の観測値のスケールがそろえられ、より正確な評価を行うことができると考え、作品の頻度分布に対して$L^2$正規化を行い、正解率の改善を目指します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDNRJhad2Zfr"
   },
   "source": [
    "### $L^2$正規化\n",
    "$L^2$正規化とは各データのベクトルの長さを1にする処理です。\n",
    "\n",
    "$$\n",
    "  \\frac{\\vec v}{\\Vert\\vec v\\Vert} =\n",
    "  \\left(\\frac{v_1}{\\sqrt{v_1^2 + \\dots + v_{16,301}^2}}, \\dots,\n",
    "    \\frac{v_{16,301}}{\\sqrt{v_1^2 + \\dots + v_{16,301}^2}}\\right)\n",
    "$$\n",
    "\n",
    "$L^2$正規化した「歯車」（`hgrm[5]`）と「蜘蛛の糸」（`hgrm[19]`）のデータを表示してみましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vTl4-Npq2ePJ"
   },
   "outputs": [],
   "source": [
    " # L2正規化を行う関数を作成&歯車と蜘蛛の糸の(正規化後の)分布を表示\n",
    "\n",
    "def l2normalize(dct): # L2正規化\n",
    "    s = np.sqrt(sum([v**2 for v in dct.values()]))\n",
    "    return dict([(k, v/s) for k, v in dct.items()]) \n",
    "\n",
    "hgrm_nrm = [l2normalize(dct) for dct in hgram] # hgramは前に作成したリスト。各作品の単語の種類とその単語の出現回数を持つ辞書型オブジェクトを作品の数だけ持つ。\n",
    "\n",
    "def countl2(n, w): # n番目の作品にwという単語が何回出現しているかを返す関数\n",
    "    if w in hgrm_nrm[n]:\n",
    "        return hgrm_nrm[n][w]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=[15,5])\n",
    "\n",
    "y = [countl2(5, w) for w in words]\n",
    "axes[0].plot(range(len(words)), y)\n",
    "axes[0].set_title('歯車', fontsize=20)\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].xaxis.set_visible(False)\n",
    "axes[0].set_yticklabels(np.round(np.arange(0, 1.1, 0.2), 1), fontsize=16)\n",
    "\n",
    "y = [countl2(19, w) for w in words]\n",
    "axes[1].plot(range(len(words)), y)\n",
    "axes[1].set_title('蜘蛛の糸', fontsize=20)\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].xaxis.set_visible(False)\n",
    "axes[1].set_yticklabels(np.round(np.arange(0, 1.1, 0.2), 1), fontsize=16)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vNMDtcxOadm"
   },
   "source": [
    "\n",
    ">上のプログラムでは`hgrm`の各要素をL2正規化して得られる配列を`hgrm_nrm`とします。\n",
    ">\n",
    ">したがって、`hgrm[i]`のL2正規化は`hgrm_nrm[i]`になります。\n",
    "\n",
    "他の作品に対しても正規化を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hzzz_R0R2f9t"
   },
   "outputs": [],
   "source": [
    " # 他の作品でもL2正規化&表示\n",
    "_, axes = plt.subplots(10, 4, figsize=[20,30])\n",
    "name = list(akutagawa_name) + list(kikuchi_name)\n",
    "for n in range(40):\n",
    "    title = name[n]\n",
    "    y = [countl2(n, w) for w in words]\n",
    "    ax = axes[int(n/4), n%4]\n",
    "    ax.plot(range(len(words)), y)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_title(title+('（芥川）' if n < 20 else '（菊池）'), fontsize=20)\n",
    "    ax.xaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siS-_u7c2ih-"
   },
   "source": [
    "$L^2$正規化する前と後で比較してみましょう。これで、分布の形状が作品の長さに依存するという問題を解消できました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xWp8Xn0x2xeY"
   },
   "outputs": [],
   "source": [
    " # 正規化する前\n",
    "_, axes = plt.subplots(10, 4, figsize=[20,30])\n",
    "for n in range(40):\n",
    "    title = name[n]\n",
    "    y = [count(n, w) for w in words]\n",
    "    ax = axes[int(n/4), n%4]\n",
    "    ax.plot(range(len(words)), y)\n",
    "    ax.set_ylim([0, 400])\n",
    "    ax.set_title(title+('（芥川）' if n < 20 else '（菊池）'), fontsize=20)\n",
    "    ax.xaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv9OAyYfP4Qt"
   },
   "source": [
    "## 2.10 学習アルゴリズムの選択(第2ラウンド)\n",
    "$L^2$正規化したベクトルに対してMDSを行い、16,301次元を3次元に圧縮してみます。k-NNアルゴリズムが有効そうであれば、引き続きk-NNアルゴリズムを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aP12vaRv23NH"
   },
   "outputs": [],
   "source": [
    "# MDSで次元圧縮\n",
    "def dl2(dictx, dicty):\n",
    "    sq = 0\n",
    "    for key in set(dictx.keys()) | set(dicty.keys()):\n",
    "        x, y = 0, 0\n",
    "        if key in dictx: \n",
    "            x = dictx[key]\n",
    "        if key in dicty:\n",
    "            y = dicty[key]\n",
    "        sq += (x - y)**2\n",
    "    return math.sqrt(sq)\n",
    "\n",
    "temp = [] \n",
    "for dictx in hgrm_nrm:\n",
    "    temp.append([dl2(dictx, dicty) for dicty in hgrm_nrm])\n",
    "dl2_matrix = np.array(temp) # 距離の行列\n",
    "\n",
    "dl2_matrix\n",
    "\n",
    "from sklearn import manifold\n",
    "mds = manifold.MDS(n_components=3, dissimilarity=\"precomputed\", random_state=6)\n",
    "pos = mds.fit_transform(dl2_matrix)\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpBz-JiG26F0"
   },
   "source": [
    "先ほどと同様に可視化してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GmrPPsBoCO3W"
   },
   "outputs": [],
   "source": [
    " # MDSで3次元に圧縮\n",
    "l1 = len(akutagawa_name)\n",
    "l2 = len(kikuchi_name)\n",
    "\n",
    "fig = go.Figure(\n",
    "    layout=go.Layout(\n",
    "    title=\"L2正規化後、ユークリッド距離に基づくデータの分布（MDSで次元圧縮）\" ,\n",
    "    showlegend=True,\n",
    "    legend=dict(x=0.7, y=0.99, xanchor='left', yanchor='top', font=dict(size=16))\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "        x = pos[0: l1,0], y = pos[0: l1,1], z = pos[0: l1,2],\n",
    "        mode = 'markers',\n",
    "        marker = dict(symbol='cross', color='black', size=5, \n",
    "                      line=dict(width=0), opacity=1 ),\n",
    "        name = '芥川'\n",
    "        )\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "        x = pos[l1: l1+l2, 0], y = pos[l1: l1+l2, 1], z = pos[l1: l1+l2, 2],\n",
    "        mode = 'markers',\n",
    "        marker = dict(symbol='circle', color='black', size=5, \n",
    "                      line=dict(width=0), opacity=1),\n",
    "        name = '菊池'\n",
    "        )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LyvSbJoqF_Y"
   },
   "source": [
    "参考程度にしかなりませんが、$L^2$正規化する前と比較して芥川と菊池のデータの凝集具合が改善されたように見えます。\\\n",
    "したがって、k-NNアルゴリズムでの正解率の上昇が期待できます。\n",
    "\n",
    "以下でも引き続きk-NNアルゴリズムを使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4buf_GRQECE"
   },
   "source": [
    "## 2.11 ハイパーパラメータの最適化とモデルの評価(第2ラウンド)\n",
    "\n",
    "第1ラウンドの場合と同様に、\n",
    "$k = 1, 2, \\dots, 10$に対して、\n",
    "5分割交差検証により予測の正解率を計算することで、最適なハイパーパラメータの値を求めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "U9XGX3yL2-vG"
   },
   "outputs": [],
   "source": [
    "# kを変化させて正解率を調べる\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "labels = [0]*l1 + [1]*l2\n",
    "\n",
    "parameters = [{'metric': ['precomputed'], 'n_neighbors': list(range(1,11))}]\n",
    "clf = GridSearchCV(KNeighborsClassifier(), parameters, cv=5)\n",
    "clf.fit(dl2_matrix, labels)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "params = clf.cv_results_[\"params\"]\n",
    "mean_test_score = clf.cv_results_[\"mean_test_score\"]\n",
    "std_test_score = clf.cv_results_[\"std_test_score\"]\n",
    "for p, m, s in zip(params, mean_test_score, std_test_score):\n",
    "    print(f\"{m:.3f} (+/- {s/2:.3f}) for {p}\")\n",
    "    x.append(p[\"n_neighbors\"])\n",
    "    y.append(m)\n",
    "\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('$k$', fontsize=16)\n",
    "plt.ylabel('正解率', fontsize=16)\n",
    "plt.bar(x, y)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckyUDa4U3BRP"
   },
   "source": [
    "$k$の最適値と、正解率の最大値は以下の通りです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9Tljxi4n2_zA"
   },
   "outputs": [],
   "source": [
    "print(f\"kの最適値:\\t{clf.best_estimator_.n_neighbors}\")\n",
    "scores = model_selection.cross_val_score(clf.best_estimator_, X = dl2_matrix, y = labels, cv = 5)\n",
    "print(f\"k={clf.best_estimator_.n_neighbors}での正解率:\\t{np.average(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFoTFJK8uGLz"
   },
   "source": [
    "正解率は上がりましたが、未だに満足できる値ではありません。探索を続けます。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hzuw7RewQVAG"
   ],
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
